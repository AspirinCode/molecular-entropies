{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try various regression models (on conformer entropy) from RDKit fingerprints (ECFP4 and ECFP6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parts based on:\n",
    "https://github.com/dkoes/qsar-tools/blob/master/trainlinearmodel.py\n",
    "\n",
    "Some parts adapted from Dan Elton\n",
    "http://moreisdifferent.com/2017/9/21/DIY-Drug-Discovery-using-molecular-fingerprints-and-machine-learning-for-solubility-prediction/\n",
    "https://github.com/delton137"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [14:09:57] Enabling RDKit 2019.09.1 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import DataStructs\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.linear_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115599\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"total-entropy.csv\")\n",
    "# drop inf and nan (i.e. some molecules from COD don't have Gasteiger charges)\n",
    "df.replace([np.inf, -np.inf], np.nan)\n",
    "df.dropna(inplace=True)\n",
    "print(len(df.index))\n",
    "# 115599 molecules left\n",
    "#  (technically we should check to make sure all the SMILES are unique!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Category', 'File', 'SMILES', 'ConfEntropy', 'VibEntropy', 'RotEntropy',\n",
      "       'TransEntropy', 'NumAtoms', 'NumBonds', 'ExactMolWt', 'Volume',\n",
      "       'NumRotorsStrict', 'NumRotors', 'NumMethyl', 'NumAmine', 'NumHydroxyl',\n",
      "       'HDonors', 'HAcceptors', 'RingCount', 'NumAromaticRings',\n",
      "       'MaxAbsPartialChg', 'MinAbsPartialChg', 'MaxPartialChg',\n",
      "       'MinPartialChg', 'TPSA', 'LabuteASA', 'MolMR', 'MolLogP', 'EState_VSA1',\n",
      "       'EState_VSA2', 'EState_VSA3', 'EState_VSA4', 'EState_VSA5',\n",
      "       'HallKierAlpha', 'BertzCT', 'BalabanJ', 'Ipc', 'Kappa1', 'Kappa2',\n",
      "       'Kappa3', 'FractionCSP3', 'NumBridgeheadAtoms', 'NumSpiroAtoms',\n",
      "       'Asphericity', 'Eccentricity', 'InertialShapeFactor',\n",
      "       'RadiusOfGyration', 'SpherocityIndex', 'ConfUnder1', 'ConfUnder2',\n",
      "       'ConfUnder3', 'ConfUnder4', 'ConfUnder5', 'ConfUnder6', 'ECFP4',\n",
      "       'ECFP6'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# what do we have\n",
    "print(df.columns)\n",
    "df = df.astype({\"NumAtoms\": int, \"NumBonds\": int, \"NumRotors\": int, \"NumMethyl\": int, \"NumAmine\": int, \"NumHydroxyl\": int, \"HDonors\": int, \"HAcceptors\": int, \"RingCount\": int, \"NumAromaticRings\": int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FPBase64ToNumpy( fps ):\n",
    "    X = []\n",
    "    for item in fps:\n",
    "        bv = DataStructs.ExplicitBitVect(4096)\n",
    "        DataStructs.ExplicitBitVect.FromBase64(bv, item)\n",
    "        arr = np.zeros( (1,) )\n",
    "        DataStructs.ConvertToNumpyArray( bv, arr )\n",
    "        X.append(arr)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = FPBase64ToNumpy(df.ECFP6)\n",
    "Y = df.ConfEntropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sometimes we need to do our own CV\n",
    "def test_model_cv(model, x, y, cv=20):\n",
    "    scores = cross_validation.cross_val_score(model, x, y, cv=cv, n_jobs=1, \n",
    "                                            scoring='mean_absolute_error')\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by evaluating several models with built-in scikit-learn CV functions:\n",
    "- Ridge regression\n",
    "- Lasso\n",
    "- ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RidgeModel = RidgeCV(scoring='neg_mean_absolute_error').fit(X,Y)\n",
    "\n",
    "RidgeModel = RidgeModel.fit(X, Y)\n",
    "mean_absolute_error(Y, RidgeModel.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lasso = LassoCV(cv=3).fit(X, Y)\n",
    "mean_absolute_error(Y, Lasso.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LassoLars = LassoLarsCV(cv=3).fit(X, Y)\n",
    "mean_absolute_error(Y, LassoLars.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ElasticModel = ElasticNetCV(cv=3, verbose=1, n_jobs=1).fit(X,Y)\n",
    "mean_absolute_error(Y, ElasticModel.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] n_estimators=50 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................. n_estimators=50, total=28.6min\n",
      "[CV] n_estimators=50 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 28.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................. n_estimators=50, total=28.5min\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] .................................. n_estimators=50, total=28.4min\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ................................. n_estimators=100, total=56.0min\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ................................. n_estimators=100, total=59.2min\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ................................. n_estimators=100, total=56.5min\n",
      "[CV] n_estimators=200 ................................................\n",
      "[CV] ................................ n_estimators=200, total=111.5min\n",
      "[CV] n_estimators=200 ................................................\n",
      "[CV] ................................ n_estimators=200, total=113.5min\n",
      "[CV] n_estimators=200 ................................................\n",
      "[CV] ................................ n_estimators=200, total=112.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 594.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Gradient Boosted model\n",
      "{'n_estimators': 200}\n",
      "6.491782656747981\n"
     ]
    }
   ],
   "source": [
    "GBmodel = GridSearchCV(GradientBoostingRegressor(), cv=3,\n",
    "              param_grid={\"n_estimators\": [50, 100, 200]}, \n",
    "              scoring='neg_mean_absolute_error',\n",
    "              verbose=2,\n",
    "              n_jobs=1)\n",
    "\n",
    "GBmodel = GBmodel.fit(X, Y)\n",
    "Best_GB = GBmodel.best_estimator_\n",
    "print(\"Best Gradient Boosted model\")\n",
    "print(GBmodel.best_params_)\n",
    "print(-1*GBmodel.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFmodel = GridSearchCV(RandomForestRegressor(), cv=3,\n",
    "              param_grid={\"n_estimators\": [50, 100, 200]}, \n",
    "              scoring='neg_mean_absolute_error',\n",
    "              verbose=2,\n",
    "              n_jobs=1)\n",
    "\n",
    "RFmodel = RFmodel.fit(X, Y)\n",
    "Best_RF = RFmodel.best_estimator_\n",
    "print(\"Best Random Forest model\")\n",
    "print(RFmodel.best_params_)\n",
    "print(-1*RFmodel.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "[CV] alpha=1e-10, gamma=1e-12, kernel=laplacian ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "KRmodel = GridSearchCV(KernelRidge(), cv=3,\n",
    "              param_grid={\n",
    "                  \"alpha\": np.logspace(-10, 0, 6),\n",
    "                  \"gamma\": np.logspace(-12, -9, 4), \n",
    "                  \"kernel\" : ['laplacian', 'rbf']}, \n",
    "              scoring='neg_mean_absolute_error',\n",
    "                       verbose=2,\n",
    "                       n_jobs=1)\n",
    "\n",
    "KRmodel = KRmodel.fit(X, Y)\n",
    "Best_KernelRidge = KRmodel.best_estimator_\n",
    "print(\"Best Kernel Ridge model\")\n",
    "print(KRmodel.best_params_)\n",
    "print(-1*KRmodel.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = [ np.log(df.NumRotors + 1), np.log(df.NumMethyl + 1) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
